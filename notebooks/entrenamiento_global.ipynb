{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68dbede",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos globales usando distintas t√©cnicas para combinar los pesos de los modelos entrenados en distintos folds de los datos de mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b91af3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee78e0",
   "metadata": {},
   "source": [
    "### Ejemplos de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4edc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('../data/x_test.npy')\n",
    "y_test = np.load('../data/y_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b053554d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_test[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ce1d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "## Abrir los modelos:\n",
    "\n",
    "import os\n",
    "loaded_local_models = [tf.keras.models.load_model(os.path.join(root, file)) for root, dirs, files in os.walk(\"../models\") for file in files if file.endswith('.keras')]\n",
    "#for i in range(len(loaded_local_models)-1):\n",
    " #   assert loaded_local_models[i].summary() == loaded_local_models[i+1].summary(), \"Models have different architectures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b49171",
   "metadata": {},
   "source": [
    "# Federated averaging\n",
    "\n",
    "**Cambiar descripci√≥n para entrega final**\n",
    "\n",
    "Federated averaging (FedAvg) is a generalization of FedSGD, which allows local nodes to perform more than one batch update on local data and exchanges the updated weights rather than the gradients. The rationale behind this generalization is that in FedSGD, if all local nodes start from the same initialization, averaging the gradients is strictly equivalent to averaging the weights themselves. Further, averaging tuned weights coming from the same initialization does not necessarily hurt the resulting averaged model's performance.[20] Variations of FedAvg based on adaptive optimizers such as ADAM and AdaGrad have been proposed, and generally outperform FedAvg.[21] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20fcc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.04      0.09      0.05       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.11      0.86      0.19       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.09     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.09      0.02     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.modelG import build\n",
    "\n",
    "local_weights = [x.get_weights() for x in loaded_local_models]\n",
    "averaged_weights = [np.mean(np.array(weights), axis=0) for weights in zip(*local_weights)]\n",
    "\n",
    "global_model = build.build_it()\n",
    "global_model.set_weights(averaged_weights)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Predict the classes for the test set\n",
    "y_pred = global_model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "global_model.save('../models/global_modelFEDAVG.keras')\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894bce13",
   "metadata": {},
   "source": [
    "# IDA (Inverse Distance Aggregation)\n",
    "\n",
    "**Cambiar para entrega final**\n",
    "\n",
    " is a novel adaptive weighting approach for clients based on meta-information which handles unbalanced and non-iid data. It uses the distance of the model parameters as a strategy to minimize the effect of outliers and improve the model's convergence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a396c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.05      0.12      0.07       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.11      0.84      0.19       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.09     10000\n",
      "   macro avg       0.02      0.10      0.03     10000\n",
      "weighted avg       0.01      0.09      0.02     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.modelG import build\n",
    "\n",
    "# Build the global model\n",
    "global_model = build.build_it()\n",
    "global_weights = global_model.get_weights()\n",
    "\n",
    "# Gather client models\n",
    "local_weights = [model.get_weights() for model in loaded_local_models]\n",
    "\n",
    "# Compute distances between each local model and the current global model\n",
    "def compute_distance(w1, w2):\n",
    "    return np.sqrt(sum([np.sum((a - b) ** 2) for a, b in zip(w1, w2)]))\n",
    "\n",
    "epsilon = 1e-10\n",
    "distances = [compute_distance(w, global_weights) for w in local_weights]\n",
    "\n",
    "# Compute inverse distance weights\n",
    "inv_dist_weights = [1 / (d + epsilon) for d in distances]\n",
    "weight_sum = sum(inv_dist_weights)\n",
    "norm_weights = [w / weight_sum for w in inv_dist_weights]\n",
    "\n",
    "# Aggregate weighted model parameters\n",
    "aggregated_weights = []\n",
    "for layer_idx, layer_weights in enumerate(zip(*local_weights)):  # Each layer across clients\n",
    "    weighted_sum = np.zeros_like(layer_weights[0])\n",
    "    for client_idx, client_weights in enumerate(local_weights):\n",
    "        weighted_sum += norm_weights[client_idx] * layer_weights[client_idx]\n",
    "    aggregated_weights.append(weighted_sum)\n",
    "    \n",
    "# Update the global model\n",
    "global_model.set_weights(aggregated_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = global_model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "global_model.save('../models/global_modelIDA.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec98552",
   "metadata": {},
   "source": [
    "# Federated stochastic gradient descent (FedSGD)\n",
    "\n",
    "**Cambiar la descripci√≥n para la entrega**\n",
    "\n",
    "Deep learning training mainly relies on variants of stochastic gradient descent, where gradients are computed on a random subset of the total dataset and then used to make one step of the gradient descent.\n",
    "\n",
    "Federated stochastic gradient descent[19] is the direct transposition of this algorithm to the federated setting, but by using a random fraction C {\\displaystyle C} of the nodes and using all the data on this node. The gradients are averaged by the server proportionally to the number of training samples on each node, and used to make a gradient descent step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1477cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\claseCloud\\federated-models\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:665: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m folds=[\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m4\u001b[39m]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m local_model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loaded_local_models)):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     x_train = np.load(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../data/x_train_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfolds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m     y_train = np.load(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../data/y_train_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolds[local_model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.modelG import build\n",
    "\n",
    "\n",
    "\n",
    "# Build the global model\n",
    "global_model = build.build_it()\n",
    "\n",
    "# Step 1: Get gradients from each local model\n",
    "grads_list = []\n",
    "folds=[0,1,4]\n",
    "for local_model in range(len(loaded_local_models)):\n",
    "    x_train = np.load(f'../data/x_train_fold_{folds[local_model]}.npy')\n",
    "    y_train = np.load(f'../data/y_train_fold_{folds[local_model]}.npy')\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = loaded_local_models[local_model](x_train, training=True)\n",
    "        loss = loaded_local_models[local_model].compiled_loss(y_train, y_pred)\n",
    "    grads = tape.gradient(loss, loaded_local_models[local_model].trainable_variables)\n",
    "    grads_list.append(grads)\n",
    "\n",
    "# Step 2: Average the gradients across clients\n",
    "average_grads = []\n",
    "for grads in zip(*grads_list):\n",
    "    stacked = np.stack([g.numpy() for g in grads], axis=0)\n",
    "    avg = np.mean(stacked, axis=0)\n",
    "    average_grads.append(tf.convert_to_tensor(avg))\n",
    "\n",
    "# Step 3: Apply the averaged gradients to the global model\n",
    "optimizer = global_model.optimizer\n",
    "optimizer.apply_gradients(zip(average_grads, global_model.trainable_variables))\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "y_pred = global_model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "global_model.save('../models/global_modelFEDSGD.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
